{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65fbdb7d",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82b573",
   "metadata": {},
   "source": [
    "Ingram 2019 reports expressions for the errors of real and imaginary parts as derived in Bendat and Piersol 2010:\n",
    "\n",
    "$$\\sigma_{Re[C]} = \\sqrt{ \\frac{P_1 P_2 + (Re[C])^2 - (Im[C])^2}{2N} }$$\n",
    "\n",
    "$$\\sigma_{Im[C]} = \\sqrt{ \\frac{P_1 P_2 - (Re[C])^2 + (Im[C])^2}{2N} }$$\n",
    "\n",
    "Here, we assume to have an ensamble or set of N lightcurves in two different energy bands, lc_list1 and lc_list2. The Cross-Spectrum C is the average of the products of FFT[LC1] and FFT[LC2]\\*, where LC1 and LC2 are single realization or elements of the lc_list1 and lc_list2 ensambles and \\* denotes complex conkucation:\n",
    "\n",
    "$$C = \\frac{1}{N} \\sum_{i=1}^N FFT[LC_{1,i}]FFT[LC_{2,i}]^{*}$$\n",
    "\n",
    "Similarly, $P_{1}$ and $P_{2}$ are average power spectra on the same ansamble of N lightcurves in the two energy bands.\n",
    "\n",
    "$saturnx$ implements power spectra and cross-spectra list, allowing then to compute average power and cross-spectra. Such averages can be computed at different \"levels\", i.e., for example, you can compute the average of all the elements of a list or sorting such elements according to certain criteria (like belonging for a specific GTI) to produce a new list. \n",
    "The previous error formulas require average Fourier products to be computed (power spectra and cross-spectrum). As it would be convenient computing the cross-spectrum error without computing the corresponding (from the same ensable) power spectra, I want to verify if the errors computed on an ensamble of N elements using the formulas above is equal to the errors obtained by weighted average of M sub-ensambles.\n",
    "\n",
    "Let's say I have two simmultaneous lightcurves in two energy bands (soft, hard): tot_lc1 and tot_lc2. I will split these two energy bands into M GTIs first and then into N segments. Each GTI will contain a number $w_g$ of segments (w stands for weight and g for GTI index). I will compute cross-spectra and errors in two ways: 1) On the ensamble of N elements using the formulas above and 2) performing a weighted average of M cross-spectra and errors computed on the M sub-ensamble each of $w_g$ elements, with $g = 0, 1, ... , M-1$. Finally, I will compare the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73a2c0a",
   "metadata": {},
   "source": [
    "# Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166116c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Volumes/Samsung_T5/saturnx')\n",
    "\n",
    "import numpy as np\n",
    "from scipy.fftpack import fftfreq, fft\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from saturnx.core.lightcurve import Lightcurve, LightcurveList\n",
    "from saturnx.core.gti import Gti\n",
    "from saturnx.core.power import PowerSpectrum\n",
    "from saturnx.utils.time_series import poi_events\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ba3672",
   "metadata": {},
   "source": [
    "# Initializing lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94614dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_white_noise_lc(tres=0.001,nbins=50000,cr=5,low_en=0.5,high_en=10):\n",
    "    events = poi_events(tres=tres,nbins=nbins,cr=cr)\n",
    "    time_bin_edges = np.linspace(0,nbins*tres,nbins+1,dtype=np.double)\n",
    "    time_bins_center = np.linspace(0+tres/2.,nbins*tres-tres/2.,nbins,dtype=np.double)\n",
    "    hist, dummy = np.histogram(events,time_bin_edges)\n",
    "    notes = {}\n",
    "    notes['STEF1'] = 'This is a test note'    \n",
    "    meta_data = {}\n",
    "    meta_data['MISSION'] = 'NICER'\n",
    "    low_en, high_en = 0.5,10\n",
    "    lc = Lightcurve(time_array = time_bins_center,count_array = hist,\n",
    "                    low_en=low_en,high_en=high_en,\n",
    "                    notes=notes, meta_data = meta_data)\n",
    "    return lc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1406a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_tot_lc = fake_white_noise_lc(low_en=0.5,high_en=2)\n",
    "hard_tot_lc = fake_white_noise_lc(low_en=2,high_en=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e81ac8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tres: 0.001\n",
      "texp: 50.0\n",
      "n_bins: 50000\n",
      "LC type <class 'saturnx.core.lightcurve.Lightcurve'>\n"
     ]
    }
   ],
   "source": [
    "print('tres:',soft_tot_lc.tres)\n",
    "print('texp:',soft_tot_lc.texp)\n",
    "print('n_bins:',len(soft_tot_lc))\n",
    "print('LC type',type(soft_tot_lc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b9981",
   "metadata": {},
   "source": [
    "# Initializing GTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e16d4deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstarts = [0.001,17,30]\n",
    "tstops  = [16,28,50]\n",
    "gti = Gti(start_array = tstarts, stop_array = tstops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaed3038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>dur</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>15.999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.000</td>\n",
       "      <td>28</td>\n",
       "      <td>11.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.000</td>\n",
       "      <td>50</td>\n",
       "      <td>20.000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start  stop     dur  gap\n",
       "0   0.001    16  15.999  0.0\n",
       "1  17.000    28  11.000  1.0\n",
       "2  30.000    50  20.000  2.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223c0eb7",
   "metadata": {},
   "source": [
    "# Splitting Lightcurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "486a8722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Splitting GTI\n",
      "===> Splitting GTI\n"
     ]
    }
   ],
   "source": [
    "soft_gti_lc_list = soft_tot_lc.split(gti)\n",
    "hard_gti_lc_list = hard_tot_lc.split(gti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3785101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Splitting Segment\n",
      "===> Splitting Segment\n",
      "===> Splitting Segment\n",
      "===> Splitting Segment\n",
      "===> Splitting Segment\n",
      "===> Splitting Segment\n"
     ]
    }
   ],
   "source": [
    "tseg = 3 # Duration of time segment in seconds\n",
    "soft_seg_lc_list = soft_gti_lc_list.split(tseg)\n",
    "hard_seg_lc_list = hard_gti_lc_list.split(tseg)\n",
    "# soft_seg_lc_list = soft_lc.split(tseg)\n",
    "# hard_seg_lc_list = hard_lc.split(tseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f38aee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014999999999999998 15.999499999999998 0.001 15.999\n",
      "17.000499999999995 27.999499999999994 0.001 11.0\n",
      "30.00049999999999 49.9995 0.001 20.0\n"
     ]
    }
   ],
   "source": [
    "# Verifying the lightcurve has been correctly split\n",
    "for lc in soft_gti_lc_list:\n",
    "    print(lc.time.iloc[0],lc.time.iloc[-1],lc.tres,lc.texp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fa9c8",
   "metadata": {},
   "source": [
    "# Extracting weights (number of segments per GTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5968ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 6]\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "first = True\n",
    "counter = 0\n",
    "for lc in soft_seg_lc_list:\n",
    "    if first:\n",
    "        first=False\n",
    "        gti_index = lc.meta_data['GTI_INDEX']\n",
    "        \n",
    "    current_gti_index = lc.meta_data['GTI_INDEX']\n",
    "    if current_gti_index == gti_index:\n",
    "        counter += 1\n",
    "    else:\n",
    "        gti_index = current_gti_index\n",
    "        weights += [counter]\n",
    "        counter=1\n",
    "weights += [counter]\n",
    "weights = np.array(weights)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3dad47",
   "metadata": {},
   "source": [
    "# Defining cross-spectrum computation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06e7db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_cross(lc1,lc2):\n",
    "    fft1 = fft(lc1.counts.to_numpy())\n",
    "    fft2 = fft(lc2.counts.to_numpy())\n",
    "    cross = np.multiply(fft1,np.conj(fft2))\n",
    "    return cross\n",
    "\n",
    "def comp_cross_err(pw1,pw2,cross,n):\n",
    "    '''\n",
    "    Following Bendat & Piersol 2010\n",
    "    '''\n",
    "    re2 = (np.real(cross))**2\n",
    "    im2 = (np.imag(cross))**2\n",
    "    dre = np.sqrt( (pw1.power*pw2.power + re2 - im2) / 2 / n )\n",
    "    dim = np.sqrt( (pw1.power*pw2.power - re2 + im2) / 2 / n )\n",
    "    return dre,dim\n",
    "\n",
    "def comp_cross_ave(lc_list1,lc_list2):\n",
    "    '''\n",
    "    Computes average Cross-Spectrum and errors over an ensamble \n",
    "    '''\n",
    "    \n",
    "    assert lc_list1 == lc_list2\n",
    "    \n",
    "    first = True\n",
    "    for lc1, lc2 in zip(lc_list1,lc_list2):\n",
    "        if first:\n",
    "            first = False\n",
    "            cross = comp_cross(lc1,lc2)\n",
    "        else:\n",
    "            cross += comp_cross(lc1,lc2)\n",
    "    average_cross = cross/len(lc_list1)\n",
    "    \n",
    "    pw_list1 = PowerSpectrum.from_lc(lc_list1)\n",
    "    pw_list2 = PowerSpectrum.from_lc(lc_list2)\n",
    "    \n",
    "    pw1 = pw_list1.average(norm=None)\n",
    "    pw2 = pw_list2.average(norm=None)\n",
    "    \n",
    "    dre,dim = comp_cross_err(pw1,pw2,average_cross,len(lc_list1))\n",
    "    return average_cross, dre, dim\n",
    "\n",
    "def comp_weighted_cross_ave(cross_array,dre_array,dim_array,weights):\n",
    "    '''\n",
    "    Computes average Cross-Spectrum and errors via weighted average\n",
    "    '''\n",
    "    assert len(cross_array) == len(dre_array)\n",
    "    assert len(cross_array) == len(dim_array)\n",
    "    assert len(cross_array) == len(weights)\n",
    "    \n",
    "    ave_cross = cross_array[0]*weights[0]\n",
    "    ave_dre2 = dre_array[0]**2*weights[0]\n",
    "    ave_dim2 = dim_array[0]**2*weights[0]\n",
    "    for i in range(1,len(cross_array)):\n",
    "        ave_cross += cross_array[i]*weights[i]\n",
    "        ave_dre2 += (dre_array[i]**2)*weights[i]\n",
    "        ave_dim2 += (dim_array[i]**2)*weights[i]\n",
    "    ave_cross = ave_cross / np.sum(weights) \n",
    "    ave_dre2 = ave_dre2 / np.sum(weights) \n",
    "    ave_dim2 = ave_dim2 / np.sum(weights) \n",
    "    \n",
    "    return ave_cross, np.sqrt(ave_dre2), np.sqrt(ave_dim2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b090b41c",
   "metadata": {},
   "source": [
    "# Computing Cross-spectrum and errors over an ensamble of N elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "986aa5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_cross_from_seg, dre_from_seg, dim_from_seg = comp_cross_ave(soft_seg_lc_list, hard_seg_lc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad28b46",
   "metadata": {},
   "source": [
    "# Computing Cross-spectrum and errors via weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c085b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing lists of segment lightcurves per GTI\n",
    "soft_lc_gti_list2 = [LightcurveList() for i in range(3)]\n",
    "hard_lc_gti_list2 = [LightcurveList() for i in range(3)]\n",
    "for lc1,lc2 in zip(soft_seg_lc_list,hard_seg_lc_list):\n",
    "    gti_index = lc1.meta_data['GTI_INDEX']\n",
    "    soft_lc_gti_list2[gti_index] += [lc1]\n",
    "    hard_lc_gti_list2[gti_index] += [lc2]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "316c13eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 5 5\n",
      "3 3 3\n",
      "6 6 6\n"
     ]
    }
   ],
   "source": [
    "# Checking correct initialization\n",
    "for item1,item2,item3 in zip(hard_lc_gti_list2,soft_lc_gti_list2,weights):\n",
    "    print(len(item1),len(item2),item3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ba124fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_gti = [comp_cross_ave(lc_list1,lc_list2)[0] for lc_list1,lc_list2 in zip(soft_lc_gti_list2,hard_lc_gti_list2)]\n",
    "dre_gti   = [comp_cross_ave(lc_list1,lc_list2)[1] for lc_list1,lc_list2 in zip(soft_lc_gti_list2,hard_lc_gti_list2)]\n",
    "dim_gti   = [comp_cross_ave(lc_list1,lc_list2)[2] for lc_list1,lc_list2 in zip(soft_lc_gti_list2,hard_lc_gti_list2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a6030ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_cross_from_gti, dre_from_gti, dim_from_gti = comp_weighted_cross_ave(cross_gti,dre_gti,dim_gti,weights=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73389fb",
   "metadata": {},
   "source": [
    "# Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bb83df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 1e-12\n",
    "assert np.allclose(ave_cross_from_seg,ave_cross_from_gti, rtol=precision, atol=precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0bd85d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7379611102885002"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dre_from_gti/dre_from_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f088276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7376743221194062"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dim_from_gti/dim_from_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7a074",
   "metadata": {},
   "source": [
    "# Comparing results for different time resolutions and gtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31c9a390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.487499999999999, 18.679499999999994, 35.37349999999999]\n",
      "[16.857499999999995, 25.033499999999993, 47.707499999999996]\n"
     ]
    }
   ],
   "source": [
    "boundaries = sorted(np.random.randint(0,len(soft_tot_lc),size=6))\n",
    "starts = [soft_tot_lc.time.iloc[boundaries[i]] for i in range(6) if i%2==0]\n",
    "stops  = [soft_tot_lc.time.iloc[boundaries[i]] for i in range(6) if i%2==1]\n",
    "\n",
    "print(starts)\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2a9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngti_array = [3,11,23]\n",
    "tseg_array = [4,6,10]\n",
    "tres_array = [0.001,0.01,0.1,1,10]\n",
    "data = []\n",
    "for tres in tres_array:\n",
    "    \n",
    "    print('='*72)\n",
    "    print('tres',tres)\n",
    "    \n",
    "    soft_tot_lc = fake_white_noise_lc(tres=tres,low_en=0.5,high_en=2)\n",
    "    hard_tot_lc = fake_white_noise_lc(tres=tres,low_en=2,high_en=10)\n",
    "    \n",
    "    for ngtis in ngti_array:\n",
    "        print('-'*72)\n",
    "        print('ngtis:',ngtis)\n",
    "        boundaries = sorted(np.random.randint(0,len(soft_tot_lc),size=ngtis))\n",
    "        tstarts = [soft_tot_lc.time.iloc[boundaries[i]] for i in range(6) if i%2==0]\n",
    "        tstops  = [soft_tot_lc.time.iloc[boundaries[i]] for i in range(6) if i%2==1]\n",
    "        gti = Gti(start_array = tstarts, stop_array = tstops)\n",
    "        \n",
    "        soft_gti_lc_list = soft_tot_lc.split(gti)\n",
    "        hard_gti_lc_list = hard_tot_lc.split(gti)\n",
    "        \n",
    "        for tseg in tseg_array:\n",
    "            print('*'*72)\n",
    "            print('tseg:',tseg)\n",
    "            soft_seg_lc_list = soft_gti_lc_list.split(tseg)\n",
    "            hard_seg_lc_list = hard_gti_lc_list.split(tseg)\n",
    "            \n",
    "            weights = []\n",
    "            first = True\n",
    "            counter = 0\n",
    "            for lc in soft_seg_lc_list:\n",
    "                if first:\n",
    "                    first=False\n",
    "                    gti_index = lc.meta_data['GTI_INDEX']\n",
    "\n",
    "                current_gti_index = lc.meta_data['GTI_INDEX']\n",
    "                if current_gti_index == gti_index:\n",
    "                    counter += 1\n",
    "                else:\n",
    "                    gti_index = current_gti_index\n",
    "                    weights += [counter]\n",
    "                    counter=1\n",
    "            weights += [counter]\n",
    "            weights = np.array(weights)\n",
    "            \n",
    "            ave_cross_from_seg, dre_from_seg, dim_from_seg = comp_cross_ave(soft_seg_lc_list, hard_seg_lc_list)\n",
    "            \n",
    "            # Initializing lists of segment lightcurves per GTI\n",
    "            soft_lc_gti_list2 = [LightcurveList() for i in range(3)]\n",
    "            hard_lc_gti_list2 = [LightcurveList() for i in range(3)]\n",
    "            for lc1,lc2 in zip(soft_seg_lc_list,hard_seg_lc_list):\n",
    "                gti_index = lc1.meta_data['GTI_INDEX']\n",
    "                soft_lc_gti_list2[gti_index] += [lc1]\n",
    "                hard_lc_gti_list2[gti_index] += [lc2] \n",
    "                \n",
    "            cross_gti = [comp_cross_ave(lc_list1,lc_list2)[0] for lc_list1,lc_list2 in zip(soft_lc_gti_list2,hard_lc_gti_list2)]\n",
    "            dre_gti   = [comp_cross_ave(lc_list1,lc_list2)[1] for lc_list1,lc_list2 in zip(soft_lc_gti_list2,hard_lc_gti_list2)]\n",
    "            dim_gti   = [comp_cross_ave(lc_list1,lc_list2)[2] for lc_list1,lc_list2 in zip(soft_lc_gti_list2,hard_lc_gti_list2)]\n",
    "            \n",
    "            precision = 1e-12\n",
    "            cond = np.allclose(ave_cross_from_seg,ave_cross_from_gti, rtol=precision, atol=precision)\n",
    "            if not cond:\n",
    "                print('Cross-spectra not so close')\n",
    "            dreratio = np.mean(dre_from_gti/dre_from_seg)\n",
    "            dimratio = np.mean(dim_from_gti/dim_from_seg)\n",
    "            print('re gti/seg',dreratio)\n",
    "            print('im gti/seg',dimratio)\n",
    "            data += [{\n",
    "                'tres':tres,\n",
    "                'gti':gti,\n",
    "                'tseg':tseg,\n",
    "                'cross_close': cond,\n",
    "                'dreratio':dreratio,\n",
    "                'dimratio':dimratio\n",
    "            }]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
